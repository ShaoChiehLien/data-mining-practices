{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Data Types, Distance Functions, Feature Extraction\n",
    "\n",
    "## Exercise 2-4: KDD Process (Solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we want to gain an insight into the big picture of knowledge discovery and mining tasks. Therefore, we will have practical introduction and discuss the KDD process upon this task.\n",
    "\n",
    "In general, the steps of the KDD process are \n",
    "1. Data Cleaning and Integration\n",
    "2. Transformation, Selection, Projection\n",
    "3. Data Mining\n",
    "4. Evaluation and Visualization\n",
    "\n",
    "Here, we focus on different aspects of these steps. In doing so, we will get to know useful python packages and functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T11:03:31.632045Z",
     "start_time": "2025-10-31T11:03:27.166183Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset\n",
    "\n",
    "The dataset we are using (`housing.csv`) is from a Kaggle competition called \"California Housing Prices - Median house prices for California districts derived from the 1990 census\" (Link to source: https://www.kaggle.com/camnugent/california-housing-prices)\n",
    "This data has contains features like population, median income, median housing price, ... for each block group (typically one block has a population of 600 to 3000 people in CA). \n",
    "\n",
    "Load the dataset into a `pandas.DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T11:33:38.535483Z",
     "start_time": "2025-10-30T11:33:38.492246Z"
    }
   },
   "outputs": [],
   "source": [
    "cal_housing = pd.read_csv('housing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the data more closely. First, we will print some samples of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-30T11:33:43.788185Z",
     "start_time": "2025-10-30T11:33:43.771663Z"
    }
   },
   "outputs": [],
   "source": [
    "cal_housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also have a more general overview of the dataset by having a look at the statistics of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_housing.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of preprocessing step (1st step in the KDD pipeline), it is also crucial to know about the datatypes and formats of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_housing.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to get a feel of the numerical attributes is to plot them in histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_housing.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the non-numerical attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_housing['ocean_proximity'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or in a more textual form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{key:value for key,value in zip(*np.unique(cal_housing['ocean_proximity'], return_counts=True))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlations in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a scatter plot matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(cal_housing, figsize=(16,16))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data cleaning\n",
    "Let's search for missing/corrupted entries in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nas = cal_housing.isna()\n",
    "nas.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 1: Delete the corresponding entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_housing = cal_housing.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 2: Drop the whole feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cal_housing = cal_housing.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 3: Introduce new values for the missing entries (zero, mean, median etc...). Has to be done with caution. Omitted here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create one-hot encoding for categorical attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before that, we replace the category 'ISLAND' by 'NEAR OCEAN' as we can hardly learn anything from 5 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_housing['ocean_proximity'] = cal_housing['ocean_proximity'].replace('ISLAND', 'NEAR OCEAN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(cal_housing['ocean_proximity'])\n",
    "one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_housing = pd.concat([cal_housing.drop('ocean_proximity', axis=1), one_hot], axis=1)\n",
    "cal_housing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How could we encode the oceaen proximity feature alternatively?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could consider it as an ordinal feature with \n",
    "\n",
    "[`INLAND`=0]\n",
    " <  \n",
    "[`<1H OCEAN`=1]\n",
    " <  \n",
    "[`NEAR BAY`=2]\n",
    " <  \n",
    "[`NEAR OCEAN`=`ISLAND`=3]. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-test Split\n",
    "Divide the Data into a Train and a Test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(cal_housing, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the target (median house value) from the covariates, i.e. create X_train, y_train, X_test, and y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_set.drop('median_house_value', axis=1)\n",
    "X_test = test_set.drop('median_house_value', axis=1)\n",
    "y_train = train_set['median_house_value']\n",
    "y_test = test_set['median_house_value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning algorithms perform best when the input numerical attributes have similar scales. Let's examing sklearn's StandardScaler to perform feature scaling on those numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = X_train.values # to numpy\n",
    "X_test = X_test.values # to numpy\n",
    "X_train[:,:-4] = scaler.fit_transform(X_train[:,:-4]) # exclude the one-hot features\n",
    "X_test[:,:-4] = scaler.transform(X_test[:,:-4]) # exclude the one-hot features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select and Train a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose one or more models from sklearn and train them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will train a linear regression model (note: this choice makes the previous feature scaling unnecessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Calculate the RÂ² score for the train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "train_score = r2_score(y_train, model.predict(X_train))\n",
    "test_score = r2_score(y_test, model.predict(X_test))\n",
    "\n",
    "train_score, test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this part, use an ordinary linear regression model trained with the data above.\n",
    "\n",
    "Plot the latitudes and longitudes of the houses in the dataset. Color the points according to the predicted house value. What can you see?\n",
    "\n",
    "Hint: Use `np.argsort()` to plot the house in ascending value-order (clearer result). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_complete = np.concatenate([X_train, X_test], axis=0)\n",
    "pred_complete = model.predict(X_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = np.argsort(pred_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_complete[order,0], X_complete[order,1], c=pred_complete[order], cmap='coolwarm', alpha=1., s=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We can see a rough outline of the state of california (not very surprising).\n",
    "2. Coastal regions seem to have more expensive houses.\n",
    "3. We can also clearly see that the regions around San Francisco and Los Angeles have the highest house values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the predictions are not linear w.r.t. latitude and longitude. How can this be explained?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_complete[order,0],pred_complete[order])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason for that is that the other covariates are not fixed in these plots. Only if we keep them constant, we can expect linearly changing predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the model and identify important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(train_set.columns)\n",
    "feature_names.remove('median_house_value')\n",
    "{feature:coef for feature, coef in zip(feature_names, model.coef_)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we scaled all features to the same scale, the absolute values of the coefficients can be seen as indicators for the feature importance.\n",
    "\n",
    "The median income seems to be the strongest predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, longitude and latitude also have a rather strong impact. How would you explain that? Justify your hypothesis with an appropriate experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We exclude longitude and latitude from the features and train the same model again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "model.fit(X_train[:,2:], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = r2_score(y_train, model.predict(X_train[:,2:]))\n",
    "test_score = r2_score(y_test, model.predict(X_test[:,2:]))\n",
    "\n",
    "train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{feature:coef for feature, coef in zip(feature_names[2:], model.coef_)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, the performance does hardly decrease. On the other hand, the coefficients for the ocean proximity features grow in absolute values while the other features coefficients remain largely the same. That is, the south-west component in latitude and longitude is used by the model as an in indicator for the ocean proximity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "nav_menu": {
   "height": "279px",
   "width": "309px"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
