{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e32bf543",
   "metadata": {},
   "source": [
    "# Exercise 3: Incremental Aggregation, Classification Evaluation\n",
    "\n",
    "## Exercise 3-3: Evaluation (Solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bb9ddd",
   "metadata": {},
   "source": [
    "## Aggregation Measures\n",
    "Given a Data Warehouse with e.g. 10 million entries, additional 1000 entries arrive each day. Rather than recomputing the desired aggregates, an incremental adaptation to the new data should be supported. In order to accelerate the (re-)computation, precomputed intermediate results shall be stored and intermediate results for the new entries shall be computed. What\n",
    "(and how many) values suffice when considering the following aggregates? For each measure note whether it is an algebraic, holistic or distributive measure.\n",
    "\n",
    "* Product\n",
    "* Mean\n",
    "* Variance\n",
    "* Median"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4944ab8",
   "metadata": {},
   "source": [
    "#### Product\n",
    "The product is a distributive aggregation measure since it is an associative pairwise operation:\n",
    "\\begin{eqnarray*}\n",
    "prod(D) &=& \\prod_{x \\in D} x \\\\\n",
    "&=& \\left( \\prod_{x \\in D_1} x \\right) \\cdot \\left( \\prod_{x \\in D_2} x \\right) \\\\\n",
    "&=& prod(prod(D_1), prod(D_2))\n",
    "\\end{eqnarray*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0414487a",
   "metadata": {},
   "source": [
    "#### Mean\n",
    "Let $D = D_1 \\cup D_2$ with $|D_1| = n_1$ and $|D_2| = n_2$ where $D_1$ is the data currently in the data warehouse and $D_2$ is the increment. It suffices to store two values for $D_1$ and $D_2$, the $sum$ and $count$, since\n",
    "\\begin{align*} \n",
    "mean(D) = \\frac{1}{n_1 + n_2} \\sum_{x \\in D} x &= \\frac{\\sum_{x \\in D_1} x + \\sum_{x \\in D_2} x}{n_1 + n_2} \\\\\n",
    "&= \\frac{sum(D_1) + sum(D_2)}{count(D_1) + count(D_2)}.\n",
    "\\end{align*}\n",
    "\n",
    "Thus, the mean is an algebraic measure. It is not a distributive measure.\n",
    "Towards contradiction assume it would, i.e. for all databases $D$ and partitions $D_1 \\uplus D_2$ it holds $mean(D) = mean(mean(D_1), mean(D_2))$, i.e. in particular for $D = \\{0, 2, 4, 6\\}$, and the partition $D = D_1 \\uplus D_2$ with $D_1 = \\{0\\}$, $D_2 = \\{2, 4, 6\\}$.\n",
    "Then \n",
    "\\begin{eqnarray*}\n",
    "\tmean(D) &=& mean(mean(D_1), mean(D_2))\\\\\n",
    "\t\\frac{0+2+4+6}{4} &=& \\frac{1}{2}\\left(\\frac{0}{1} + \\frac{2+4+6}{3}\\right)\\\\\n",
    "\t\\frac{12}{4} &=& \\frac{1}{2} \\cdot \\frac{12}{3}\\\\\n",
    "\t3 &=& 2\n",
    "\\end{eqnarray*}\n",
    "which is a contradiction.\n",
    "\n",
    "To further derive the conditions when the distribution works, consider\n",
    "\\begin{eqnarray*}\n",
    "\tmean(D) &=& mean(mean(D_1), mean(D_2))\\\\\n",
    "\t\\frac{1}{n_1+n_2} \\sum_{x \\in D} x &=& \\frac{1}{2} \\left( \\frac{1}{n_1} \\sum_{x \\in D_1} x + \\frac{1}{n_2} \\sum_{x \\in D_2} x \\right)\\\\\n",
    "\t\\frac{1}{n_1 + n_2} \\sum_{x \\in D_1} x + \\frac{1}{n_1 + n_2} \\sum_{x \\in D_2} x &=& \\frac{1}{2n_1} \\sum_{x \\in D_1} x + \\frac{1}{2n_2} \\sum_{x \\in D_2} x\\\\\n",
    "\t\\left(\\frac{1}{n_1 + n_2} - \\frac{1}{2n_1}\\right) \\sum_{x \\in D_1} x &=& \\left(\\frac{1}{2n_2} - \\frac{1}{n_1 + n_2}\\right) \\sum_{x \\in D_2} x\\\\\n",
    "\t\\left(\\frac{2n_1 - (n_1 + n_2)}{2n_1(n_1 + n_2)}\\right) \\sum_{x \\in D_1} x &=& \\left(\\frac{n_1 + n_2 - 2n_2}{2n_2(n_1 + n_2)}\\right) \\sum_{x \\in D_2} x\\\\\n",
    "\t\\left(\\frac{n_1 - n_2}{2n_1(n_1 + n_2)}\\right) \\sum_{x \\in D_1} x &=& \\left(\\frac{n_1 - n_2}{2n_2(n_1 + n_2)}\\right) \\sum_{x \\in D_2} x\\\\\n",
    "\t\\left(\\frac{n_1 - n_2}{n_1}\\right) \\sum_{x \\in D_1} x &=& \\left(\\frac{n_1 - n_2}{n_2}\\right) \\sum_{x \\in D_2} x\\\\\n",
    "\t\\frac{1}{n_1} \\sum_{x \\in D_1} x &=& \\frac{1}{n_2} \\sum_{x \\in D_2} x\n",
    "\\end{eqnarray*}\n",
    "The last operation is only an equivalence if $n_1 \\neq n_2$.\n",
    "If $n_1 = n_2$, the statement holds trivially.\n",
    "Concluding, the mean can be computed in distributive manner if and only if the partitions have same size, or the same mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7015d64",
   "metadata": {},
   "source": [
    "#### Variance\n",
    "\n",
    "Similarly, the variance is also an algebraic measure:\n",
    "\\begin{eqnarray*} \n",
    "var(D) &=& \\frac{1}{n_1 + n_2 - 1} \\left( \\sum_{x \\in D} x^2 - \\frac{1}{n_1 + n_2} \\left( \\sum_{x \\in D} x \\right)^2 \\right)\\\\\n",
    "&=& \\frac{1}{n_1 + n_2 - 1} \\left( \\sum_{x \\in D} x^2 - \\frac{1}{n_1 + n_2} \\left( \\sum_{x \\in D} x^2 + \\sum_{x \\in D_1, y \\in D_2} xy + \\sum_{x \\in D_1, y \\in D_2} yx \\right) \\right) \\\\\n",
    "&=& \\frac{1}{n_1 + n_2 - 1} \\left( \\sum_{x \\in D} x^2 - \\frac{1}{n_1 + n_2} \\left( \\sum_{x \\in D_1} x^2 + \\sum_{x \\in D_2} x^2 + 2 \\left( \\sum_{x \\in D_1} x \\right) \\left( \\sum_{x \\in D_2} x \\right) \\right) \\right) \\\\\n",
    "&=& \\frac{ss(D_1) + ss(D_2) - \\frac{1}{count(D_1) + count(D_2)} \\left( ss(D_1) + ss(D_2) + 2 \\cdot sum(D_1) \\cdot sum(D_2) \\right)}{count(D_1) + count(D_2) - 1}\n",
    "\\end{eqnarray*}\n",
    "We need to store three values, the $sum$, $count$ and additionally the sum of squares ($ss$). Note that the variance is not distributive, since the information about central tendency is lost (the variance is shift-invariant). The variance $var(D)$ depends on where $D_1$ and $D_2$ are located in the data space and in general there is no way to infer that from $var(D_1)$ and $var(D_2)$ alone. However, if $mean(D_1) = mean(D_2) = 0$, one can show that\n",
    "$var(D) = \\frac{n_1}{n_1 + n_2} var(D_1) + \\frac{n_2}{n_1 + n_2} var(D_2).$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d81161d",
   "metadata": {},
   "source": [
    "#### Median\n",
    "The median is a classical holistic measure which means intuitively that we need to look at the whole data at once in order to compute it. For the median to be an algebraic measure, we would need to be able to represent the median of $D$ as an algebraic function of constant size aggregates of $D_1$ and $D_2$. Assume that we have computed such aggregates. Now the idea is that for any two sets $D_1$ and $D_2$, we can construct an example where the $k$-th element of $D_1$ (or $D_2$) is the median. That is, we potentially need to access every single element in $D_1$ (or $D_2$) from a constant size aggregate. This is clearly not possible. Thus, we need to look at the whole sets $D_1$ and $D_2$ together in order to find the median, i.e. the median is a holistic measure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d4470f",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "### Implementation\n",
    "First, we want to get more familiar with the notions seen in the lecture. For each of the metrics below, implement a function that computes it (when given an array of binary target values and an array of binary predictions):\n",
    "* TP\n",
    "* TN\n",
    "* FP\n",
    "* FN\n",
    "* Accuracy\n",
    "* Precision\n",
    "* Recall\n",
    "* F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e9e1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TP(y_true, y_pred):\n",
    "    return np.sum(np.logical_and(y_true==1, y_pred==1))\n",
    "\n",
    "def TN(y_true, y_pred):\n",
    "    return np.sum(np.logical_and(y_true==0, y_pred==0))\n",
    "\n",
    "def FP(y_true, y_pred):\n",
    "    return np.sum(np.logical_and(y_true==0, y_pred==1))\n",
    "\n",
    "def FN(y_true, y_pred):\n",
    "    return np.sum(np.logical_and(y_true==1, y_pred==0))\n",
    "\n",
    "def Accuracy(y_true, y_pred):\n",
    "    tp = TP(y_true, y_pred)\n",
    "    tn = TN(y_true, y_pred)\n",
    "    return (tp + tn) / len(y_true)\n",
    "\n",
    "def Precision(y_true, y_pred):\n",
    "    tp = TP(y_true, y_pred)\n",
    "    fp = FP(y_true, y_pred)\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "def Recall(y_true, y_pred):\n",
    "    tp = TP(y_true, y_pred)\n",
    "    fn = FN(y_true, y_pred)\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "def F1(y_true, y_pred):\n",
    "    tp = TP(y_true, y_pred)\n",
    "    fp = FP(y_true, y_pred)   \n",
    "    fn = FN(y_true, y_pred)\n",
    "    return 2*tp / (2*tp + fn + fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a71a372",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "What is a major shortcoming of the accuracy as a metric? Design a scenarion that demonstrates this. What would be a sensible alternative in your scenario?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39da845c",
   "metadata": {},
   "source": [
    "The accuracy is not reliable for imbalanced data. For instance, consider a disease that only occurs in 1% percent of the observed cases. Then, a useless classifier that always predicts that the disease is not present achieves an accuracy of 99%.\n",
    "\n",
    "We take the recall into account, we see that it is 0 with this classifier. Hence, we should try to build a classifier that achieves a higher recall, in order to detect many people with the disease and select them for further investigations. But, we should simultaneously keep the precision on a sensible level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b09276",
   "metadata": {},
   "source": [
    "### Relation of Precision, Recall and F1 measure\n",
    "\n",
    "Show that F1 measure is the harmonic mean of precision and recall, i.e. the reciprocal of the arithmetic mean of reciprocals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed55666",
   "metadata": {},
   "source": [
    "$$ F1 = \\frac{2 \\cdot Prec  \\cdot Rec}{Prec + Rec} \n",
    "= \\left(\\frac{Prec + Rec}{2 \\cdot Prec  \\cdot Rec} \\right)^{-1}\n",
    "= \\left(\\frac{Prec}{2 \\cdot Prec  \\cdot Rec} + \\frac{Rec}{2 \\cdot Prec  \\cdot Rec}\\right)^{-1}\n",
    "= \\left(\\frac{1}{2}\\left(\\frac{1}{Prec} + \\frac{1}{Rec}\\right)\\right)^{-1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ab6590",
   "metadata": {},
   "source": [
    "So, what does this mean practically? To find out, visualize the F1 measure as a function of precision and recall and compare it to the minimum and the arithmetic mean/average of precision and recall. Describe your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7097df0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "precision = np.linspace(0.01,1,100)\n",
    "recall = np.linspace(0.01,1,100)\n",
    "f1 = np.zeros((len(precision), len(recall)))\n",
    "minimum = np.zeros((len(precision), len(recall)))\n",
    "avg = np.zeros((len(precision), len(recall)))\n",
    "\n",
    "for i in range(len(precision)):\n",
    "    for j in range(len(recall)):\n",
    "        f1[i,j] = 2*precision[i]*recall[j] / (precision[i] + recall[j])\n",
    "        minimum[i,j] = min(precision[i], recall[j])\n",
    "        avg[i,j] = (precision[i] + recall[j]) / 2\n",
    "        \n",
    "plt.imshow(f1)\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel('Recall')\n",
    "plt.title('F1')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "\n",
    "# compare to avg and minimum\n",
    "plt.imshow(avg)\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel('Recall')\n",
    "plt.title('Average')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(minimum)\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel('Recall')\n",
    "plt.title('Minimum')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc20024",
   "metadata": {},
   "source": [
    "Apparently, the F1 measure is more sensitive to small values than the arithmetic mean (similar to the minimum, which is only dependent on the smaller value). Thus, it provides a sensible way of balancing precision and recall. In contrast to that, the arithmetic mean still achieves a value of 0.5 if the precision is 1 and the recall is 0 (vice versa)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2a1434",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149c82e3",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "Implement a class that allows you to run a k-fold cross validation when given a number of folds k, a dataset X with targets y, an untrained model that has functions `fit(X,y)` and `predict(X)` and a metric that follows the signature from above. The result of the cross-validation should be a list/array of the scores obtained for each test fold.\n",
    "\n",
    "Hint: Be careful that the model is trained from scratch for every fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2488fcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "class CV:\n",
    "    def __init__(self, k, X, y, metric):\n",
    "        self.k = k\n",
    "        self.n = len(X)\n",
    "        n_k = self.n // self.k\n",
    "        order = np.arange(self.n)\n",
    "        np.random.shuffle(order)\n",
    "        self.X_k = [X[order][i*n_k:(i+1)*n_k] for i in range(self.k)]\n",
    "        self.y_k = [y[order][i*n_k:(i+1)*n_k] for i in range(self.k)]\n",
    "        self.metric = metric\n",
    "        \n",
    "    def run(self, model):        \n",
    "        scores = []\n",
    "        for i in range(self.k):\n",
    "            model_i = clone(model)\n",
    "            score_i = self.run_single_fold(model_i, i)\n",
    "            scores.append(score_i)\n",
    "        return scores\n",
    "            \n",
    "    def run_single_fold(self, model, fold):\n",
    "        X_train = np.concatenate([self.X_k[i] for i in range(self.k) if i != fold], axis=0)\n",
    "        y_train = np.concatenate([self.y_k[i] for i in range(self.k) if i != fold], axis=0)\n",
    "        X_test = self.X_k[fold]\n",
    "        y_test = self.y_k[fold]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        score = self.metric(y_test, y_pred)\n",
    "        return score\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b288c889",
   "metadata": {},
   "source": [
    "Test your class for `sklearn.linear_model.LogisticRegression`, your implementation of the accuracy and the Iris dataset where we are only interested in class 1 for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad842f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "X,y = load_iris(return_X_y=True)\n",
    "y = (y == 1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7360a80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CV(k=5,\n",
    "        X=X,\n",
    "        y=y,\n",
    "        metric=Accuracy)\n",
    "scores = cv.run(LogisticRegression())\n",
    "scores, np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43c8b7c",
   "metadata": {},
   "source": [
    "### Determinacy\n",
    "Is k-fold cross validation deterministic (assuming that model training and prediction is deterministic)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee69a607",
   "metadata": {},
   "source": [
    "In general, cross validation is not determistic because the splits can vary. However, for k=n, i.e. leave-one-out cross validation, the result will be deterministic as the splits will be also deterministic in this case. A downside of leave-one-out cross validation is that we have to fit n models which may be computationally intractable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a68f55-f6d1-417d-a141-fe2ed94fbef9",
   "metadata": {},
   "source": [
    "# Bias Variance\n",
    "\n",
    "Consider the following experiment:\n",
    "\n",
    "* INPUT: dataset X, targets y, proportion p\n",
    "* split X and y randomly in train and test set with training proportion p\n",
    "* train a model and the resulting training data\n",
    "* evalute the model on the test data\n",
    "* OUTPUT: test score\n",
    "\n",
    "What can you say about the bias-variance tradeoff (depending on p) in this scenario?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa1d2d2-9476-4355-96f8-6fe52765bb0e",
   "metadata": {},
   "source": [
    "## Bias-Variance Tradeoff Overview\n",
    "\n",
    "In machine learning, model error can be decomposed into:\n",
    "\n",
    "* Bias: Error due to overly simplistic assumptions in the model. High bias means the model underfits.\n",
    "* Variance: Error due to sensitivity to small fluctuations in the training set. High variance means the model overfits.\n",
    "* Irreducible Error: Noise in the data we can't eliminate.\n",
    "\n",
    "The tradeoff is about balancing bias and variance to minimize total error.\n",
    "\n",
    "### Imagine This\n",
    "You train the same model 5 times, each time using a slightly different training set (randomly sampled from the same full dataset). Then you test it on the same test set.\n",
    "\n",
    "* If the predictions (or test scores) are very similar each time ‚Üí Low variance\n",
    "* If the predictions jump around a lot ‚Üí High variance\n",
    "\n",
    "This ‚Äújumpiness‚Äù is the spread we‚Äôre measuring\n",
    "\n",
    "### Why It Matters\n",
    "\n",
    "High variance means the model is unstable ‚Äî it learns too much from the quirks of each training set.\n",
    "That instability makes it less reliable on new data. So even if it performs well on one training set, it might flop on another.\n",
    "\n",
    "### Key Insight\n",
    "* As ùëù increases:\n",
    "    - Bias decreases (better learning)\n",
    "    - Variance increases (less reliable evaluation)\n",
    "* As ùëù decreases:\n",
    "    - Bias increases (poor learning)\n",
    "    - Variance decreases (more stable evaluation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
